{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1631,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_columns=['Freq_Of_Word_33', 'Freq_Of_Word_50', 'Freq_Of_Word_36',\n",
    "       'Freq_Of_Word_29', 'Freq_Of_Word_46', 'Freq_Of_Word_45',\n",
    "       'Freq_Of_Word_27', 'Freq_Of_Word_37', 'Freq_Of_Word_3',\n",
    "       'Freq_Of_Word_18', 'Freq_Of_Word_17', 'Freq_Of_Word_5',\n",
    "       'StylizedLetters', 'Freq_Of_Word_2', 'Freq_Of_Word_6', 'Freq_Of_Word_8',\n",
    "       'Freq_Of_Word_19', 'Freq_Of_Word_25', 'Freq_Of_Word_20',\n",
    "       'LengthOFFirstParagraph', 'Freq_Of_Word_11', 'Freq_Of_Word_16',\n",
    "       'Freq_Of_Word_24', 'Freq_Of_Word_23', 'Freq_Of_Word_7',\n",
    "       'Freq_Of_Word_21','IsGoodNews']\n",
    "Testing=['Freq_Of_Word_33', 'Freq_Of_Word_50', 'Freq_Of_Word_36',\n",
    "       'Freq_Of_Word_29', 'Freq_Of_Word_46', 'Freq_Of_Word_45',\n",
    "       'Freq_Of_Word_27', 'Freq_Of_Word_37', 'Freq_Of_Word_3',\n",
    "       'Freq_Of_Word_18', 'Freq_Of_Word_17', 'Freq_Of_Word_5',\n",
    "       'StylizedLetters', 'Freq_Of_Word_2', 'Freq_Of_Word_6', 'Freq_Of_Word_8',\n",
    "       'Freq_Of_Word_19', 'Freq_Of_Word_25', 'Freq_Of_Word_20',\n",
    "       'LengthOFFirstParagraph', 'Freq_Of_Word_11', 'Freq_Of_Word_16',\n",
    "       'Freq_Of_Word_24', 'Freq_Of_Word_23', 'Freq_Of_Word_7',\n",
    "       'Freq_Of_Word_21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from operator import itemgetter\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc,recall_score,precision_score\n",
    "import datetime as dt\n",
    "\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"Train.csv\")\n",
    "df_test=pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train=df_train[Training_columns]\n",
    "# df_test=df_test[Testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1643,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined=pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused=['Freq_Of_Word_1',\n",
    " 'Freq_Of_Word_4',\n",
    " 'Freq_Of_Word_15',\n",
    " 'Freq_Of_Word_26',\n",
    " 'Freq_Of_Word_30',\n",
    " 'Freq_Of_Word_31',\n",
    " 'Freq_Of_Word_35',\n",
    " 'Freq_Of_Word_38',\n",
    " 'Freq_Of_Word_39',\n",
    " 'Freq_Of_Word_41',\n",
    " 'Freq_Of_Word_43',\n",
    " 'Freq_Of_Word_44',\n",
    " 'Freq_Of_Word_47',\n",
    " 'Freq_Of_Word_48',\n",
    " 'Freq_Of_Word_32', 'Freq_Of_Word_40', 'Freq_Of_Word_34']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1645,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Freq_Of_Word_1' 'Freq_Of_Word_4' 'Freq_Of_Word_15' 'Freq_Of_Word_26'\\n 'Freq_Of_Word_30' 'Freq_Of_Word_31' 'Freq_Of_Word_35' 'Freq_Of_Word_38'\\n 'Freq_Of_Word_39' 'Freq_Of_Word_41' 'Freq_Of_Word_43' 'Freq_Of_Word_44'\\n 'Freq_Of_Word_47' 'Freq_Of_Word_48' 'Freq_Of_Word_32' 'Freq_Of_Word_40'\\n 'Freq_Of_Word_34'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1645-1b40e9ff90ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Freq_Of_Word_1' 'Freq_Of_Word_4' 'Freq_Of_Word_15' 'Freq_Of_Word_26'\\n 'Freq_Of_Word_30' 'Freq_Of_Word_31' 'Freq_Of_Word_35' 'Freq_Of_Word_38'\\n 'Freq_Of_Word_39' 'Freq_Of_Word_41' 'Freq_Of_Word_43' 'Freq_Of_Word_44'\\n 'Freq_Of_Word_47' 'Freq_Of_Word_48' 'Freq_Of_Word_32' 'Freq_Of_Word_40'\\n 'Freq_Of_Word_34'] not found in axis\""
     ]
    }
   ],
   "source": [
    "combined.drop(unused,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=combined.iloc[:947,]\n",
    "df_test=combined.iloc[947:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1639,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.sqrt(df_train.iloc[:,:-1]+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1642,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_train.drop(labels=['IsGoodNews'], axis=1),df_train['IsGoodNews'],test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params={'colsample_bytree': 1.0,\n",
    "#   'gamma': 2,\n",
    "#   'max_depth': 6,\n",
    "#   'min_child_weight': 1,\n",
    "#   'n_estimators': 200,\n",
    "#   'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 1622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = XGBClassifier()\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.9107142857142857\n",
      "Accuracy Score = 92.98\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(\"F1 score \" + f1_score(Y_test, predictions).astype(str))\n",
    "score=round(rf.score(X_test, Y_test) * 100, 2)\n",
    "print(\"Accuracy Score = \"+score.astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.drop(zero,axis=1)\n",
    "X_test=X_test.drop(zero,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: Freq_Of_Word_2, importance: 0.009026425890624523\n",
      "feature: Freq_Of_Word_3, importance: 0.00523829460144043\n",
      "feature: Freq_Of_Word_5, importance: 0.012201576493680477\n",
      "feature: Freq_Of_Word_6, importance: 0.0021538562141358852\n",
      "feature: Freq_Of_Word_7, importance: 0.1265682578086853\n",
      "feature: Freq_Of_Word_8, importance: 0.05335995554924011\n",
      "feature: Freq_Of_Word_9, importance: 0.0033796695061028004\n",
      "feature: Freq_Of_Word_10, importance: 0.013258102349936962\n",
      "feature: Freq_Of_Word_11, importance: 0.021975239738821983\n",
      "feature: Freq_Of_Word_12, importance: 0.00896446406841278\n",
      "feature: Freq_Of_Word_13, importance: 0.03835540637373924\n",
      "feature: Freq_Of_Word_14, importance: 0.0003693341859616339\n",
      "feature: Freq_Of_Word_16, importance: 0.024287249892950058\n",
      "feature: Freq_Of_Word_17, importance: 0.01606958732008934\n",
      "feature: Freq_Of_Word_18, importance: 0.006735493894666433\n",
      "feature: Freq_Of_Word_19, importance: 0.006926134694367647\n",
      "feature: Freq_Of_Word_20, importance: 0.052473533898591995\n",
      "feature: Freq_Of_Word_21, importance: 0.038789015263319016\n",
      "feature: Freq_Of_Word_22, importance: 0.002673680894076824\n",
      "feature: Freq_Of_Word_23, importance: 0.051261212676763535\n",
      "feature: Freq_Of_Word_24, importance: 0.1935579478740692\n",
      "feature: Freq_Of_Word_25, importance: 0.09865663200616837\n",
      "feature: Freq_Of_Word_27, importance: 0.05891774594783783\n",
      "feature: Freq_Of_Word_28, importance: 0.007607753854244947\n",
      "feature: Freq_Of_Word_29, importance: 0.01086708065122366\n",
      "feature: Freq_Of_Word_33, importance: 0.011070946231484413\n",
      "feature: Freq_Of_Word_36, importance: 0.014025438576936722\n",
      "feature: Freq_Of_Word_37, importance: 0.013777532614767551\n",
      "feature: Freq_Of_Word_42, importance: 0.009937427937984467\n",
      "feature: Freq_Of_Word_45, importance: 0.007404543925076723\n",
      "feature: Freq_Of_Word_46, importance: 0.036441199481487274\n",
      "feature: Freq_Of_Word_49, importance: 0.007636982016265392\n",
      "feature: Freq_Of_Word_50, importance: 0.0033380663953721523\n",
      "feature: TotalEmojiCharacters, importance: 0.014406553469598293\n",
      "feature: LengthOFFirstParagraph, importance: 0.012989012524485588\n",
      "feature: StylizedLetters, importance: 0.0052985455840826035\n"
     ]
    }
   ],
   "source": [
    "zero=[]\n",
    "for feat, importance in zip(X_train.columns, rf.feature_importances_):\n",
    "    print('feature: {f}, importance: {i}'.format(f=feat, i=importance))\n",
    "    if(importance>0.007):\n",
    "        zero.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Submission\n",
    "# df_train=combined.iloc[:947,]\n",
    "# df_test=combined.iloc[947:,]\n",
    "\n",
    "# Y_train = df_train['IsGoodNews']\n",
    "# X_train = df_train.drop('IsGoodNews', axis=1)\n",
    "\n",
    "# rf = XGBClassifier()\n",
    "# rf.fit(X_train,Y_train)\n",
    "\n",
    "# pred = rf.predict(df_test.drop([\"IsGoodNews\"],axis=1))\n",
    "\n",
    "# submission=pd.DataFrame(pred,columns=[\"IsGoodNews\"])\n",
    "\n",
    "\n",
    "# submission=pd.DataFrame(pred,columns=[\"IsGoodNews\"])\n",
    "# submission.IsGoodNews=submission.IsGoodNews.astype(int)\n",
    "# submission.to_excel(\"submission.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "execution_count": 1477,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "#plot_importance(rf, max_num_features=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Freq_Of_Word_7': 11.723599699096152,\n",
       " 'Freq_Of_Word_24': 17.92863190225,\n",
       " 'Freq_Of_Word_16': 2.249647695293549,\n",
       " 'TotalEmojiCharacters': 1.3344314088688887,\n",
       " 'Freq_Of_Word_8': 4.9425564479999995,\n",
       " 'Freq_Of_Word_13': 3.55273438,\n",
       " 'Freq_Of_Word_19': 0.6415449236194302,\n",
       " 'StylizedLetters': 0.4907867659535133,\n",
       " 'Freq_Of_Word_21': 3.592898462190817,\n",
       " 'Freq_Of_Word_12': 0.8303486575166666,\n",
       " 'Freq_Of_Word_46': 3.375427938513043,\n",
       " 'Freq_Of_Word_5': 1.1301917220380953,\n",
       " 'LengthOFFirstParagraph': 1.2031292324041665,\n",
       " 'Freq_Of_Word_18': 0.623886516452941,\n",
       " 'Freq_Of_Word_37': 1.2761672270875,\n",
       " 'Freq_Of_Word_10': 1.2280542199624997,\n",
       " 'Freq_Of_Word_33': 1.0254650793333333,\n",
       " 'Freq_Of_Word_23': 4.748156783714285,\n",
       " 'Freq_Of_Word_20': 4.860449856666667,\n",
       " 'Freq_Of_Word_25': 9.138237924294115,\n",
       " 'Freq_Of_Word_27': 5.457356082529412,\n",
       " 'Freq_Of_Word_45': 0.6858584201575758,\n",
       " 'Freq_Of_Word_49': 0.7073883956666666,\n",
       " 'Freq_Of_Word_11': 2.035493776655555,\n",
       " 'Freq_Of_Word_17': 1.4884726430125,\n",
       " 'Freq_Of_Word_14': 0.0342102051,\n",
       " 'Freq_Of_Word_28': 0.7046810983333334,\n",
       " 'Freq_Of_Word_50': 0.30919406618985507,\n",
       " 'Freq_Of_Word_2': 0.8360879812500001,\n",
       " 'Freq_Of_Word_3': 0.48520588966666667,\n",
       " 'Freq_Of_Word_6': 0.19950457843636366,\n",
       " 'Freq_Of_Word_36': 1.29912996,\n",
       " 'Freq_Of_Word_42': 0.9204710649999999,\n",
       " 'Freq_Of_Word_29': 1.0065817525,\n",
       " 'Freq_Of_Word_22': 0.247654229,\n",
       " 'Freq_Of_Word_9': 0.313047618}"
      ]
     },
     "execution_count": 1478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero=[]\n",
    "for feat, importance in zip(X_train.columns, rf.feature_importances_):\n",
    "    #print('feature: {f}, importance: {i}'.format(f=feat, i=importance))\n",
    "    if(importance==0.0):\n",
    "        zero.append(feat)\n",
    "X_train=X_train.drop(zero,axis=1)\n",
    "X_test=X_test.drop(zero,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 36)"
      ]
     },
     "execution_count": 1276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation of : <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "CV score = 90.88\n",
      "F1 Score score = 0.8807339449541284\n",
      "Cross-validation of : <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "CV score = 88.42\n",
      "F1 Score score = 0.8450704225352113\n",
      "Cross-validation of : <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "CV score = 85.26\n",
      "F1 Score score = 0.8359375000000001\n",
      "Cross-validation of : <class 'sklearn.svm._classes.LinearSVC'>\n",
      "CV score = 91.23\n",
      "F1 Score score = 0.8868778280542986\n",
      "Cross-validation of : <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "CV score = 92.98\n",
      "F1 Score score = 0.9090909090909092\n",
      "Cross-validation of : <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "CV score = 93.33\n",
      "F1 Score score = 0.9155555555555556\n",
      "Cross-validation of : <class 'xgboost.sklearn.XGBClassifier'>\n",
      "CV score = 92.98\n",
      "F1 Score score = 0.9107142857142857\n",
      "Cross-validation of : <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "CV score = 85.96\n",
      "F1 Score score = 0.8275862068965518\n"
     ]
    }
   ],
   "source": [
    "def compute_score(clf, X, y, scoring='accuracy'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n",
    "    return np.mean(xval)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "xgb=XGBClassifier()\n",
    "gaussian = GaussianNB()\n",
    "linear_svc = LinearSVC()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "#perceptron = Perceptron(max_iter=5)\n",
    "rf = RandomForestClassifier()\n",
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "models = [logreg,knn,gaussian, linear_svc,rf, gboost,xgb,decision_tree ]\n",
    "for model in models:\n",
    "    print ('Cross-validation of : {0}'.format(model.__class__))\n",
    "    #score = compute_score(clf=model, X=X_train, y=Y_train, scoring='accuracy')\n",
    "    model.fit(X_train,Y_train)\n",
    "    score=round(model.score(X_test, Y_test) * 100, 2)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = f1_score(Y_test, predictions)\n",
    "    print ('CV score = {0}'.format(score))\n",
    "    print ('F1 Score score = {0}'.format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 1427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "gboost.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.9155555555555556\n",
      "Accuracy Score = 93.33\n"
     ]
    }
   ],
   "source": [
    "predictions = gboost.predict(X_test)\n",
    "print(\"F1 score \" + f1_score(Y_test, predictions).astype(str))\n",
    "score=round(gboost.score(X_test, Y_test) * 100, 2)\n",
    "print(\"Accuracy Score = \"+score.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00036933, 0.00215386, 0.00267368, 0.00333807, 0.00337967,\n",
       "       0.00523829, 0.00529855, 0.00673549, 0.00692613, 0.00740454,\n",
       "       0.00760775, 0.00763698, 0.00896446, 0.00902643, 0.00993743,\n",
       "       0.01086708, 0.01107095, 0.01220158, 0.01298901, 0.0132581 ,\n",
       "       0.01377753, 0.01402544, 0.01440655, 0.01606959, 0.02197524,\n",
       "       0.02428725, 0.0364412 , 0.03835541, 0.03878902, 0.05126121,\n",
       "       0.05247353, 0.05335996, 0.05891775, 0.09865663, 0.12656826,\n",
       "       0.19355795], dtype=float32)"
      ]
     },
     "execution_count": 1425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=36, Accuracy: 91.07%\n",
      "92.98\n",
      "Thresh=0.000, n=35, Accuracy: 90.58%\n",
      "92.63\n",
      "Thresh=0.001, n=34, Accuracy: 89.69%\n",
      "91.93\n",
      "Thresh=0.002, n=33, Accuracy: 90.58%\n",
      "92.63\n",
      "Thresh=0.002, n=32, Accuracy: 89.69%\n",
      "91.93\n",
      "Thresh=0.002, n=31, Accuracy: 89.29%\n",
      "91.58\n",
      "Thresh=0.003, n=30, Accuracy: 90.58%\n",
      "92.63\n",
      "Thresh=0.003, n=29, Accuracy: 90.58%\n",
      "92.63\n",
      "Thresh=0.003, n=28, Accuracy: 89.78%\n",
      "91.93\n",
      "Thresh=0.003, n=27, Accuracy: 90.18%\n",
      "92.28\n",
      "Thresh=0.003, n=26, Accuracy: 89.78%\n",
      "91.93\n",
      "Thresh=0.003, n=25, Accuracy: 90.58%\n",
      "92.63\n",
      "Thresh=0.003, n=24, Accuracy: 91.07%\n",
      "92.98\n",
      "Thresh=0.004, n=23, Accuracy: 90.58%\n",
      "92.63\n",
      "Thresh=0.004, n=22, Accuracy: 88.79%\n",
      "91.23\n",
      "Thresh=0.004, n=21, Accuracy: 88.39%\n",
      "90.88\n",
      "Thresh=0.005, n=20, Accuracy: 90.27%\n",
      "92.28\n",
      "Thresh=0.005, n=19, Accuracy: 89.87%\n",
      "91.93\n",
      "Thresh=0.006, n=18, Accuracy: 90.18%\n",
      "92.28\n",
      "Thresh=0.007, n=17, Accuracy: 89.19%\n",
      "91.58\n",
      "Thresh=0.009, n=16, Accuracy: 89.69%\n",
      "91.93\n",
      "Thresh=0.010, n=15, Accuracy: 89.69%\n",
      "91.93\n",
      "Thresh=0.010, n=14, Accuracy: 90.50%\n",
      "92.63\n",
      "Thresh=0.011, n=13, Accuracy: 88.39%\n",
      "90.88\n",
      "Thresh=0.021, n=12, Accuracy: 87.11%\n",
      "89.82\n",
      "Thresh=0.026, n=11, Accuracy: 88.79%\n",
      "91.23\n",
      "Thresh=0.033, n=10, Accuracy: 87.50%\n",
      "90.18\n",
      "Thresh=0.039, n=9, Accuracy: 88.39%\n",
      "90.88\n",
      "Thresh=0.047, n=8, Accuracy: 88.21%\n",
      "90.53\n",
      "Thresh=0.049, n=7, Accuracy: 87.50%\n",
      "90.18\n",
      "Thresh=0.055, n=6, Accuracy: 87.39%\n",
      "90.18\n",
      "Thresh=0.065, n=5, Accuracy: 83.49%\n",
      "87.37\n",
      "Thresh=0.086, n=4, Accuracy: 79.81%\n",
      "84.91\n",
      "Thresh=0.110, n=3, Accuracy: 78.92%\n",
      "83.51\n",
      "Thresh=0.166, n=2, Accuracy: 74.77%\n",
      "80.35\n",
      "Thresh=0.201, n=1, Accuracy: 67.44%\n",
      "80.35\n"
     ]
    }
   ],
   "source": [
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "thresholds = sort(gboost.feature_importances_)\n",
    "#thresholds=0.0001\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(gboost, threshold=thresh, prefit=True)\n",
    "    #print(selection)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    # train model\n",
    "    selection_model =XGBClassifier()\n",
    "    selection_model.fit(select_X_train, Y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    predictions = selection_model.predict(select_X_test)\n",
    "    accuracy = f1_score(Y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "    \n",
    "    print(round(selection_model.score(select_X_test, Y_test) * 100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181818181818182\n",
      "93.68\n"
     ]
    }
   ],
   "source": [
    "selection = SelectFromModel(rf, threshold=0.011,prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "selection_model = XGBClassifier()\n",
    "select_X_test = selection.transform(X_test)\n",
    "selection_model.fit(select_X_train, Y_train)\n",
    "predictions = selection_model.predict(select_X_test)\n",
    "\n",
    "\n",
    "print(f1_score(Y_test, predictions))\n",
    "\n",
    "print(round(selection_model.score(select_X_test, Y_test) * 100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f4': 10.222218174784375,\n",
       " 'f16': 18.573691408875,\n",
       " 'f9': 2.487695826896666,\n",
       " 'f23': 1.3252714983518528,\n",
       " 'f5': 5.074714666666666,\n",
       " 'f14': 3.3906279474280705,\n",
       " 'f12': 0.6362194196542186,\n",
       " 'f25': 0.5775644683737933,\n",
       " 'f8': 0.672654474566842,\n",
       " 'f21': 3.4462683501181828,\n",
       " 'f2': 0.9582119617190473,\n",
       " 'f24': 0.8131934163067301,\n",
       " 'f11': 0.8034660356588235,\n",
       " 'f19': 1.1136618061444445,\n",
       " 'f6': 0.6100751391444444,\n",
       " 'f15': 5.023194334428569,\n",
       " 'f13': 3.797238353125,\n",
       " 'f17': 7.914196375823531,\n",
       " 'f18': 5.831433379941178,\n",
       " 'f20': 0.9512116545250002,\n",
       " 'f22': 0.3516628102316456,\n",
       " 'f1': 0.5518536402727272,\n",
       " 'f7': 1.0138162530000001,\n",
       " 'f0': 0.9561603277142857,\n",
       " 'f10': 2.0680133884,\n",
       " 'f3': 0.2136137507}"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       174\n",
      "         1.0       0.93      0.90      0.91       111\n",
      "\n",
      "    accuracy                           0.93       285\n",
      "   macro avg       0.93      0.93      0.93       285\n",
      "weighted avg       0.93      0.93      0.93       285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('XGBClassifier: ')\n",
    "print(metrics.classification_report(Y_test, rf.predict(X_test)))\n",
    "\n",
    "#print(metrics.confusion_matrix(expected_y, predicted_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = df_train['IsGoodNews']\n",
    "# X_train = df_train.drop('IsGoodNews', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'max_depth': [2,3,4,5,6],\n",
    "#                        'n_estimators': [i for i in range(100,600,50)], \n",
    "#                        'gamma': [i/10.0 for i in range(3,6)],\n",
    "#                        'subsample':[i/10.0 for i in range(6,10)],\n",
    "#                        'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "#                        'max_depth': [2,3,4,5,6],\n",
    "#                        'learning_rate' : [0.03,0.08,0,1,0.3,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         'n_estimators' : [800],\n",
    "#         'min_child_weight': [1, 2, 13],\n",
    "#         'gamma': [0.5, 1, 1.5],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'max_depth': [6,7,8,12]\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 972 out of 972 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9078023638140941,\n",
       " {'colsample_bytree': 0.8,\n",
       "  'gamma': 1.5,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 800,\n",
       "  'subsample': 0.6})"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf = XGBClassifier(nthread=-1) \n",
    "# clf = GridSearchCV(rf,params,\n",
    "#                     cv=3,\n",
    "#                     verbose=1, \n",
    "#                     scoring='f1',\n",
    "#                       n_jobs=4,)\n",
    "\n",
    "# clf.fit(X_train,Y_train)\n",
    "# clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "par={'colsample_bytree': 1.0,\n",
    "  'gamma': 2,\n",
    "  'max_depth': 6,\n",
    "  'min_child_weight': 1,\n",
    "  'n_estimators': 200,\n",
    "  'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=800, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = XGBClassifier(n_estimators=800)\n",
    "rf.fit(X_train,Y_train)\n",
    "#rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(df_test)\n",
    "submission=pd.DataFrame(pred,columns=[\"IsGoodNews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.IsGoodNews=submission.IsGoodNews.astype(int)\n",
    "submission.to_excel(\"submission.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: Freq_Of_Word_2, importance: 0.006537522189319134\n",
      "feature: Freq_Of_Word_3, importance: 0.0066892788745462894\n",
      "feature: Freq_Of_Word_5, importance: 0.009110324084758759\n",
      "feature: Freq_Of_Word_6, importance: 0.003647834761068225\n",
      "feature: Freq_Of_Word_7, importance: 0.15155702829360962\n",
      "feature: Freq_Of_Word_8, importance: 0.025289153680205345\n",
      "feature: Freq_Of_Word_9, importance: 0.0033671611454337835\n",
      "feature: Freq_Of_Word_10, importance: 0.010341299697756767\n",
      "feature: Freq_Of_Word_11, importance: 0.004198987036943436\n",
      "feature: Freq_Of_Word_12, importance: 0.007514134515076876\n",
      "feature: Freq_Of_Word_13, importance: 0.010913271456956863\n",
      "feature: Freq_Of_Word_14, importance: 0.0027278789784759283\n",
      "feature: Freq_Of_Word_16, importance: 0.0325244665145874\n",
      "feature: Freq_Of_Word_17, importance: 0.01315219420939684\n",
      "feature: Freq_Of_Word_18, importance: 0.006506460718810558\n",
      "feature: Freq_Of_Word_19, importance: 0.006160132121294737\n",
      "feature: Freq_Of_Word_20, importance: 0.025597285479307175\n",
      "feature: Freq_Of_Word_21, importance: 0.02347511798143387\n",
      "feature: Freq_Of_Word_22, importance: 0.008839783258736134\n",
      "feature: Freq_Of_Word_23, importance: 0.031575001776218414\n",
      "feature: Freq_Of_Word_24, importance: 0.3263486325740814\n",
      "feature: Freq_Of_Word_25, importance: 0.05026772990822792\n",
      "feature: Freq_Of_Word_27, importance: 0.054397113621234894\n",
      "feature: Freq_Of_Word_28, importance: 0.02068653516471386\n",
      "feature: Freq_Of_Word_29, importance: 0.016338340938091278\n",
      "feature: Freq_Of_Word_33, importance: 0.012046772986650467\n",
      "feature: Freq_Of_Word_36, importance: 0.010364264249801636\n",
      "feature: Freq_Of_Word_37, importance: 0.009543153457343578\n",
      "feature: Freq_Of_Word_42, importance: 0.013408119790256023\n",
      "feature: Freq_Of_Word_45, importance: 0.011501324363052845\n",
      "feature: Freq_Of_Word_46, importance: 0.0392555333673954\n",
      "feature: Freq_Of_Word_49, importance: 0.011477794498205185\n",
      "feature: Freq_Of_Word_50, importance: 0.0032928946893662214\n",
      "feature: TotalEmojiCharacters, importance: 0.016025710850954056\n",
      "feature: LengthOFFirstParagraph, importance: 0.009026283398270607\n",
      "feature: StylizedLetters, importance: 0.006295459810644388\n"
     ]
    }
   ],
   "source": [
    "zero=[]\n",
    "for feat, importance in zip(X_train.columns, rf.feature_importances_):\n",
    "    print('feature: {f}, importance: {i}'.format(f=feat, i=importance))\n",
    "    if(importance==0.0):\n",
    "        zero.append(feat)\n",
    "#print(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-886-c02173120709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# select features using threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mselect_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mselection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     75\u001b[0m         X = check_array(X, dtype=None, accept_sparse='csr',\n\u001b[1;32m     76\u001b[0m                         force_all_finite=not tags.get('allow_nan', True))\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             warn(\"No features were selected: either the data is\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mget_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/feature_selection/_from_model.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0;34m' \"prefit=True\" while passing the fitted'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              ' estimator to the constructor.')\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/feature_selection/_from_model.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, norm_order)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature_importances_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcoef_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mcoef_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                  .format(self.booster))\n\u001b[1;32m    715\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdump_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;31m# Logic for multiclass classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_classes_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weight'"
     ]
    }
   ],
   "source": [
    "# from numpy import sort\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# thresholds = sort(model.feature_importances_)\n",
    "# #thresholds=0.0001\n",
    "# for thresh in thresholds:\n",
    "# \t# select features using threshold\n",
    "# \tselection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "# \tselect_X_train = selection.transform(X_train)\n",
    "# \t# train model\n",
    "# \tselection_model = XGBClassifier(n_estimators=800,max_depth=6)\n",
    "# \tselection_model.fit(select_X_train, Y_train)\n",
    "# \t# eval model\n",
    "# \tselect_X_test = selection.transform(X_test)\n",
    "# \tpredictions = selection_model.predict(select_X_test)\n",
    "# \taccuracy = f1_score(Y_test, predictions)\n",
    "# \tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Freq_Of_Word_1',\n",
       " 'Freq_Of_Word_4',\n",
       " 'Freq_Of_Word_15',\n",
       " 'Freq_Of_Word_26',\n",
       " 'Freq_Of_Word_30',\n",
       " 'Freq_Of_Word_31',\n",
       " 'Freq_Of_Word_35',\n",
       " 'Freq_Of_Word_38',\n",
       " 'Freq_Of_Word_39',\n",
       " 'Freq_Of_Word_41',\n",
       " 'Freq_Of_Word_43',\n",
       " 'Freq_Of_Word_44',\n",
       " 'Freq_Of_Word_47',\n",
       " 'Freq_Of_Word_48']"
      ]
     },
     "execution_count": 1024,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing features with zero importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(zero,axis=1,inplace=True)\n",
    "X_test.drop(zero,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Cofficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 selected features\n"
     ]
    }
   ],
   "source": [
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "cor_support, cor_feature = cor_selector(X_train,Y_train,28)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features=cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[final_features]\n",
    "X_test=X_test[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 28)"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.21264\n",
      "Feature: 1, Score: 0.14982\n",
      "Feature: 2, Score: 0.47828\n",
      "Feature: 3, Score: 0.32341\n",
      "Feature: 4, Score: 0.99029\n",
      "Feature: 5, Score: 0.20221\n",
      "Feature: 6, Score: 0.37474\n",
      "Feature: 7, Score: -0.06352\n",
      "Feature: 8, Score: -0.00950\n",
      "Feature: 9, Score: -0.38829\n",
      "Feature: 10, Score: 0.01947\n",
      "Feature: 11, Score: -0.16252\n",
      "Feature: 12, Score: 0.40795\n",
      "Feature: 13, Score: 0.50619\n",
      "Feature: 14, Score: 0.21775\n",
      "Feature: 15, Score: -0.07359\n",
      "Feature: 16, Score: 0.01217\n",
      "Feature: 17, Score: 1.12457\n",
      "Feature: 18, Score: 0.66939\n",
      "Feature: 19, Score: 0.41936\n",
      "Feature: 20, Score: 1.16286\n",
      "Feature: 21, Score: 1.58165\n",
      "Feature: 22, Score: -1.57297\n",
      "Feature: 23, Score: -1.10277\n",
      "Feature: 24, Score: -2.29432\n",
      "Feature: 25, Score: 0.31839\n",
      "Feature: 26, Score: -0.79296\n",
      "Feature: 27, Score: -0.38263\n",
      "Feature: 28, Score: -0.65837\n",
      "Feature: 29, Score: -0.43205\n",
      "Feature: 30, Score: -0.99162\n",
      "Feature: 31, Score: -0.60125\n",
      "Feature: 32, Score: 0.59423\n",
      "Feature: 33, Score: -0.10576\n",
      "Feature: 34, Score: -0.89960\n",
      "Feature: 35, Score: -1.04642\n",
      "Feature: 36, Score: -0.95992\n",
      "Feature: 37, Score: -0.37003\n",
      "Feature: 38, Score: -0.81874\n",
      "Feature: 39, Score: -0.59652\n",
      "Feature: 40, Score: -1.94199\n",
      "Feature: 41, Score: -0.15263\n",
      "Feature: 42, Score: -0.32338\n",
      "Feature: 43, Score: -0.23254\n",
      "Feature: 44, Score: 0.71735\n",
      "Feature: 45, Score: 0.50230\n",
      "Feature: 46, Score: 0.63121\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "#X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X_train, Y_train)\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SUbmission\n",
    "\n",
    "df_train=combined.iloc[:947,]\n",
    "df_test=combined.iloc[947:,]\n",
    "\n",
    "Y_train = df_train['IsGoodNews']\n",
    "X_train = df_train.drop('IsGoodNews', axis=1)\n",
    "X_train=X_train[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = XGBClassifier(n_estimators=800,max_depth=6)\n",
    "rf.fit(X_train,Y_train)\n",
    "pred = rf.predict(df_test)\n",
    "submission=pd.DataFrame(pred,columns=[\"IsGoodNews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = XGBClassifier(n_estimators=800,max_depth=6)\n",
    "rf.fit(X_train,Y_train)\n",
    "pred = rf.predict(df_test)\n",
    "submission=pd.DataFrame(pred,columns=[\"IsGoodNews\"])\n",
    "submission.IsGoodNews=submission.IsGoodNews.astype(int)\n",
    "submission.to_excel(\"submission.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
